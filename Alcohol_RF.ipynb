{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pool0/home/sanjay.r/anaconda3/envs/sergio_rotation/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load node information\n",
    "\n",
    "spoke = np.load('../../psev_repo/PSEV_matrix')\n",
    "sep = np.load('../../psev_repo/PSEV_SEP_map')\n",
    "spoke_node = np.load('../../psev_repo/PSEV_SPOKE_node_map')\n",
    "\n",
    "spoke = pd.DataFrame(spoke, columns=spoke_node)\n",
    "spoke.index = sep\n",
    "spoke.index = spoke.index.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "spoke.columns = spoke.columns.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "node_type = np.load('../../psev_repo/node_type_list.npy')\n",
    "node_type = [x.decode('utf-8') if isinstance(x, bytes) else x for x in node_type]\n",
    "node_type = pd.DataFrame({\n",
    "    'node': spoke.columns,\n",
    "    'type': node_type\n",
    "})\n",
    "\n",
    "unique_node_types = node_type['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translating conditions\n",
    "# disease_annotation = pd.read_csv('../../psev_repo/omop_sep_map/filtered_omop_conditions_to_spoke_extended_2.tsv', sep = '\\t')\n",
    "\n",
    "disease_annotation = pd.read_csv('../../gbellucci/spoke_linkers/omop2spoke_combined.tsv', sep = '\\t')\n",
    "disease_annotation.rename(columns={'OMOP': 'condition_concept_id'}, inplace=True)\n",
    "disease_annotation.rename(columns={'SPOKE': 'spoke_concept_id'}, inplace=True)\n",
    "\n",
    "spoke_to_omop_dict = dict(zip(disease_annotation['spoke_concept_id'], disease_annotation['condition_concept_id']))\n",
    "\n",
    "\n",
    "#Translating Drugs\n",
    "drug_annotation = pd.read_csv('../../psev_repo/omop_sep_map/filtered_omop_drug_exposure_to_spoke_extended.tsv', sep = '\\t')\n",
    "drug_annotation.rename(columns={'OMOP': 'condition_concept_id'}, inplace=True)\n",
    "drug_annotation.rename(columns={'SPOKE': 'spoke_concept_id'}, inplace=True)\n",
    "\n",
    "spoke_to_omop_dict.update(dict(zip(drug_annotation['spoke_concept_id'], drug_annotation['condition_concept_id'])))\n",
    "\n",
    "\n",
    "#Translating measurements\n",
    "lab_annotation = pd.read_csv('../../psev_repo/omop_sep_map/filtered_omop_measurement_to_spoke_extended.tsv', sep = '\\t')\n",
    "lab_annotation.rename(columns={'OMOP': 'condition_concept_id'}, inplace=True)\n",
    "lab_annotation.rename(columns={'SPOKE': 'spoke_concept_id'}, inplace=True)\n",
    "\n",
    "spoke_to_omop_dict.update(dict(zip(lab_annotation['spoke_concept_id'], lab_annotation['condition_concept_id'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble table to train on in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First load the general top 30% PSEVs\n",
    "\n",
    "pat_ids = np.load('data/alc_psevs/person_id_index.npy')\n",
    "columns = np.load('data/alc_psevs/filtered_patient_psevs_columns.npy', allow_pickle=True)\n",
    "psevs = np.load('data/alc_psevs/filtered_patient_psevs.npy')\n",
    "\n",
    "full_bio_cohort = pd.read_feather('data/alc_cohort_details.feather')\n",
    "full_bio_cohort['dependent'] = full_bio_cohort['most_frequent_condition'].notna()\n",
    "label_dict = dict(zip(full_bio_cohort[\"person_id\"], full_bio_cohort[\"dependent\"]))\n",
    "\n",
    "#Now load the node specific ones\n",
    "\n",
    "# Initialize empty arrays for columns and psevs\n",
    "nt_columns = None\n",
    "nt_psevs = None\n",
    "\n",
    "for nt in unique_node_types:\n",
    "    ind_nt_psevs = np.load(f'data/alc_nt_psevs/filtered_patient_psevs_{nt}.npy')\n",
    "    ind_nt_columns = np.load(f'data/alc_nt_psevs/filtered_patient_psevs_columns_{nt}.npy', allow_pickle=True)\n",
    "\n",
    "    # Concatenate columns and psevs\n",
    "    if nt_columns is None:\n",
    "        nt_columns = ind_nt_columns\n",
    "    else:\n",
    "        nt_columns = np.concatenate((nt_columns, ind_nt_columns))  # Add new columns\n",
    "\n",
    "    if nt_psevs is None:\n",
    "        nt_psevs = ind_nt_psevs\n",
    "    else:\n",
    "        nt_psevs = np.hstack((nt_psevs, ind_nt_psevs))  # Add new data horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24951, 116357)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psevs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116357,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116778,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format tables for RF\n",
    "Y = np.array([label_dict[pid] for pid in pat_ids if pid in label_dict])\n",
    "X = psevs\n",
    "nt_X = nt_psevs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runGenericRF(X, Y, name):\n",
    "    # Split data into training and testing sets (80% train, 20% test)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_features=int(np.sqrt(X.shape[1])), random_state=42)\n",
    "\n",
    "    # Train the model on the training data\n",
    "    rf_clf.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    Y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(f\"{name} Model accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    dump(rf_clf, f'models/alcohol_rf_model_{name}.joblib')\n",
    "\n",
    "    return accuracy, rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_general, model_general = runGenericRF(X, Y, \"general\")\n",
    "\n",
    "accuracy_nt, model_nt = runGenericRF(nt_X, Y, \"nt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sergio_rotation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
